# ============================================================================
# KAFKA MULTI-AUTH DOCKER COMPOSE
# ============================================================================
# Single broker with multiple listeners for testing all authentication types:
#
#   Port   | Protocol        | Auth Type        | Credentials
#   -------|-----------------|------------------|---------------------------
#   29092  | PLAINTEXT       | None             | (no auth)
#   29093  | SASL_PLAINTEXT  | SASL/PLAIN       | testuser / testpass
#   29094  | SASL_PLAINTEXT  | SASL/SCRAM       | scramuser / scrampass
#   29095  | SASL_SSL        | SASL/SSL         | testuser / testpass + TLS
#   29096  | SSL             | SSL (one-way)    | CA cert only
#   29097  | SSL             | mTLS             | client cert + key
#
# Prerequisites:
#   1. Run scripts/create-certs.sh to generate certificates
#   2. Run: docker-compose up -d
#   3. SCRAM users are auto-created by the init container
#
# Kafka UI: http://localhost:8083
# ============================================================================

name: kafka-multi-auth

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1
    container_name: zookeeper
    hostname: zookeeper
    restart: always
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - kafka-net

  broker:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka
    hostname: kafka
    restart: always
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
      - "29093:29093"
      - "29094:29094"
      - "29095:29095"
      - "29096:29096"
      - "29097:29097"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

      # ---- LISTENERS (6 protocols) ----
      KAFKA_LISTENERS: >-
        INTERNAL://0.0.0.0:9092,
        PLAINTEXT_HOST://0.0.0.0:29092,
        SASL_PLAIN://0.0.0.0:29093,
        SASL_SCRAM://0.0.0.0:29094,
        SASL_SSL_HOST://0.0.0.0:29095,
        SSL_HOST://0.0.0.0:29096,
        MTLS_HOST://0.0.0.0:29097

      KAFKA_ADVERTISED_LISTENERS: >-
        INTERNAL://kafka:9092,
        PLAINTEXT_HOST://localhost:29092,
        SASL_PLAIN://localhost:29093,
        SASL_SCRAM://localhost:29094,
        SASL_SSL_HOST://localhost:29095,
        SSL_HOST://localhost:29096,
        MTLS_HOST://localhost:29097

      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: >-
        INTERNAL:PLAINTEXT,
        PLAINTEXT_HOST:PLAINTEXT,
        SASL_PLAIN:SASL_PLAINTEXT,
        SASL_SCRAM:SASL_PLAINTEXT,
        SASL_SSL_HOST:SASL_SSL,
        SSL_HOST:SSL,
        MTLS_HOST:SSL

      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      # ---- SASL Configuration ----
      KAFKA_OPTS: "-Djava.security.auth.login.config=/etc/kafka/kafka_server_jaas.conf"

      # SASL mechanisms per listener
      KAFKA_LISTENER_NAME_SASL__PLAIN_SASL_ENABLED_MECHANISMS: PLAIN
      KAFKA_LISTENER_NAME_SASL__SCRAM_SASL_ENABLED_MECHANISMS: SCRAM-SHA-256,SCRAM-SHA-512
      KAFKA_LISTENER_NAME_SASL__SSL__HOST_SASL_ENABLED_MECHANISMS: PLAIN

      # ---- SSL Configuration ----
      KAFKA_SSL_KEYSTORE_LOCATION: /etc/kafka/secrets/kafka.broker.keystore.jks
      KAFKA_SSL_KEYSTORE_PASSWORD: changeit
      KAFKA_SSL_KEY_PASSWORD: changeit
      KAFKA_SSL_TRUSTSTORE_LOCATION: /etc/kafka/secrets/kafka.broker.truststore.jks
      KAFKA_SSL_TRUSTSTORE_PASSWORD: changeit

      # SSL listener (one-way) - no client auth
      KAFKA_LISTENER_NAME_SSL__HOST_SSL_CLIENT_AUTH: none

      # mTLS listener - require client cert
      KAFKA_LISTENER_NAME_MTLS__HOST_SSL_CLIENT_AUTH: required

      # ---- Stability (single node) ----
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

    volumes:
      - kafka_data:/var/lib/kafka/data
      - ./config/kafka_server_jaas.conf:/etc/kafka/kafka_server_jaas.conf:ro
      - ./config/certs:/etc/kafka/secrets:ro
    networks:
      - kafka-net

  # Init container: creates SCRAM users after broker is ready
  kafka-init:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka-init
    depends_on:
      - broker
    entrypoint: ["/bin/bash", "/scripts/create-scram-users.sh"]
    volumes:
      - ./scripts/create-scram-users.sh:/scripts/create-scram-users.sh:ro
    networks:
      - kafka-net
    restart: "no"

  schema-registry:
    image: confluentinc/cp-schema-registry:7.6.1
    container_name: schema-registry
    hostname: schema-registry
    restart: always
    depends_on:
      - broker
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:9092
    networks:
      - kafka-net

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    restart: always
    depends_on:
      - broker
    ports:
      - "8083:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: multi-auth
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8081
      DYNAMIC_CONFIG_ENABLED: "true"
    networks:
      - kafka-net

volumes:
  kafka_data:
    driver: local

networks:
  kafka-net:
    driver: bridge
